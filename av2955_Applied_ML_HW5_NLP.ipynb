{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "coms-w4995",
      "language": "python",
      "name": "coms-w4995"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "Applied_ML_HW5_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9bcdbd2-3401-41ad-a83f-830e9346e607"
      },
      "source": [
        "# **Applied Machine Learning Homework 5**\n",
        "**Due 2 May, 2022 (Monday) 11:59PM EST**\n",
        "\n",
        "**Name: Aayush Kumar Verma** <br>\n",
        "**UNI: av2955**"
      ],
      "id": "d9bcdbd2-3401-41ad-a83f-830e9346e607"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70df26be-5638-4b0d-a252-4437eb76aa46"
      },
      "source": [
        "### Natural Language Processing\n",
        "We will train a supervised training model to predict if a tweet has a positive or negative sentiment."
      ],
      "id": "70df26be-5638-4b0d-a252-4437eb76aa46"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e0d9a19-25ea-4490-b0e8-7909bcdc3d9d"
      },
      "source": [
        "####  **Dataset loading & dev/test splits**"
      ],
      "id": "2e0d9a19-25ea-4490-b0e8-7909bcdc3d9d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fafa37c4-c8fc-4697-9bbe-11539d710bf7"
      },
      "source": [
        "**1.1) Load the twitter dataset from NLTK library**"
      ],
      "id": "fafa37c4-c8fc-4697-9bbe-11539d710bf7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f4ce405-237b-42d2-9c81-25ff28deaf4a",
        "outputId": "72a3fd57-8e59-4be2-db37-3d0a089f1a9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('twitter_samples')\n",
        "from nltk.corpus import twitter_samples "
      ],
      "id": "5f4ce405-237b-42d2-9c81-25ff28deaf4a",
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c41d62ce-3c78-4b6c-9238-111d990d170f"
      },
      "source": [
        "**1.2) Load the positive & negative tweets**"
      ],
      "id": "c41d62ce-3c78-4b6c-9238-111d990d170f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b92fb408-f72a-4c23-acd8-7c944a52edd3"
      },
      "source": [
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "id": "b92fb408-f72a-4c23-acd8-7c944a52edd3",
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12eae071-fd8a-4a46-9958-0525c635fd88"
      },
      "source": [
        "**1.3) Create a development & test split (80/20 ratio):**"
      ],
      "id": "12eae071-fd8a-4a46-9958-0525c635fd88"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f3673db-d7a8-470b-a3d3-f4522cd359b8"
      },
      "source": [
        "#code here\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "id": "0f3673db-d7a8-470b-a3d3-f4522cd359b8",
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_dev_positive, x_test_positive, x_dev_negative, x_test_negative = train_test_split(all_positive_tweets, all_negative_tweets, random_state = 42, test_size=0.2)\n",
        "x_dev = x_dev_positive + x_dev_negative\n",
        "x_test = x_test_positive + x_test_negative\n",
        "y_dev = [1] * len(x_dev_positive) + [0] * len(x_dev_negative)\n",
        "y_test = [1] * len(x_test_positive) + [0] * len(x_test_negative)"
      ],
      "metadata": {
        "id": "c_8DGJ69Tcw7"
      },
      "id": "c_8DGJ69Tcw7",
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (x_dev[:10])\n",
        "print ('--------')\n",
        "print (x_test[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0vLs3jBISsR",
        "outputId": "1f3faebf-7c04-4b23-f267-791e46ad4bdc"
      },
      "id": "W0vLs3jBISsR",
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['@seananmcguire my best friend Carina is one here in San Francisco. Let me know if you want to get I touch. :)', 'That also means, imma go back to being more twitter active :D\\nCause I know everyone missed me ;) xD', '@MsKristinKreuk Hugs ang Kisses from the philippines :)', 'Please comment on what you think of what I wrote so far in the twitlonger :)', 'This girl :)  https://t.co/OAXMGGICNr', \"@grrl_afraid Oh course, I gained weight bcus I used to be a rubbish veggie but now I've learned to balance everything now! :-)\", '@Satbains1 Congratulations Sat on your 3rd honorary degree from everyone at Alacer :)', '@Geordnet hehe cool :)', '@Wilma2207fWilma haha! Thank you! :) üç∞', 'Hi BAM ! @BarsAndMelody \\nCan you follow my bestfriend @969Horan696 ? \\nShe loves you a lot :) \\nSee you in Warsaw &lt;3 \\nLove you &lt;3 x10']\n",
            "--------\n",
            "['@Sanza_T @LeratoTmohale Does the bag do the job Sanza?  :-)', '@WeAlwaysChillin This sounds nice :D', \"@wishinguponstar We couldn't have said it better ourselves, Kelly! So glad you're enjoying your nibbles :)\", 'Chaerin unnie : )', 'A very productive day so far :) Happy Days...!!  :) :) but my head is spinning with things, those voices keep calling..!!! Lol \\U000fe334', '@twentyonepilots @fujirock_jp tylers hipster glasses :D', '@clivewalker near enough to Dartmoor :)', '@simonxxx_ follback :)', 'Stats for the day have arrived. 2 new followers and NO unfollowers :) via http://t.co/6LyskBfqFG.', 'ROFL! Shades of Grey - netsec edition :-) https://t.co/PHpzRakSgU']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32b23398-e80e-4624-b89e-c02fabfd3f8d"
      },
      "source": [
        "#### **Data preprocessing**\n",
        "We will do some data preprocessing before we tokenize the data. We will remove `#` symbol, hyperlinks, stop words & punctuations from the data. You can use the `re` package in python to find and replace these strings. "
      ],
      "id": "32b23398-e80e-4624-b89e-c02fabfd3f8d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f89d9d69-1640-4583-a7b7-7ec04ccf3310"
      },
      "source": [
        "**1.4) Replace the `#` symbol with '' in every tweet**"
      ],
      "id": "f89d9d69-1640-4583-a7b7-7ec04ccf3310"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5db4dd6d-e775-49d3-96e1-57620c042d46"
      },
      "source": [
        "#code here\n",
        "\n",
        "x_dev = [word.replace(\"#\", \"\") for word in x_dev]\n",
        "x_test = [word.replace(\"#\", \"\") for word in x_test]"
      ],
      "id": "5db4dd6d-e775-49d3-96e1-57620c042d46",
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (x_dev[:10])\n",
        "print ('--------')\n",
        "print (x_test[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiZPKx43KA_E",
        "outputId": "5dda9e45-ea1f-40e3-85d0-2bbcee60cde7"
      },
      "id": "BiZPKx43KA_E",
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['@seananmcguire my best friend Carina is one here in San Francisco. Let me know if you want to get I touch. :)', 'That also means, imma go back to being more twitter active :D\\nCause I know everyone missed me ;) xD', '@MsKristinKreuk Hugs ang Kisses from the philippines :)', 'Please comment on what you think of what I wrote so far in the twitlonger :)', 'This girl :)  https://t.co/OAXMGGICNr', \"@grrl_afraid Oh course, I gained weight bcus I used to be a rubbish veggie but now I've learned to balance everything now! :-)\", '@Satbains1 Congratulations Sat on your 3rd honorary degree from everyone at Alacer :)', '@Geordnet hehe cool :)', '@Wilma2207fWilma haha! Thank you! :) üç∞', 'Hi BAM ! @BarsAndMelody \\nCan you follow my bestfriend @969Horan696 ? \\nShe loves you a lot :) \\nSee you in Warsaw &lt;3 \\nLove you &lt;3 x10']\n",
            "--------\n",
            "['@Sanza_T @LeratoTmohale Does the bag do the job Sanza?  :-)', '@WeAlwaysChillin This sounds nice :D', \"@wishinguponstar We couldn't have said it better ourselves, Kelly! So glad you're enjoying your nibbles :)\", 'Chaerin unnie : )', 'A very productive day so far :) Happy Days...!!  :) :) but my head is spinning with things, those voices keep calling..!!! Lol \\U000fe334', '@twentyonepilots @fujirock_jp tylers hipster glasses :D', '@clivewalker near enough to Dartmoor :)', '@simonxxx_ follback :)', 'Stats for the day have arrived. 2 new followers and NO unfollowers :) via http://t.co/6LyskBfqFG.', 'ROFL! Shades of Grey - netsec edition :-) https://t.co/PHpzRakSgU']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24c4caa8-d71d-46a8-8859-a8e85c56acfe"
      },
      "source": [
        "**1.5) Replace hyperlinks with '' in every tweet**"
      ],
      "id": "24c4caa8-d71d-46a8-8859-a8e85c56acfe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff5a7411-df49-427b-adef-5e8e63224db0"
      },
      "source": [
        "#code here\n",
        "\n",
        "regex = 'https?://[a-z]*.[a-z]*(/[a-zA-Z0-9]*)?'\n",
        "x_dev = [re.sub(regex, repl='', string=word) for word in x_dev]\n",
        "x_test = [re.sub(regex, repl='', string=word) for word in x_test]"
      ],
      "id": "ff5a7411-df49-427b-adef-5e8e63224db0",
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (x_dev[:10])\n",
        "print ('--------')\n",
        "print (x_test[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV94FZkdIkNW",
        "outputId": "1e3c7c47-0c77-4a42-894f-0c3681d4d1e8"
      },
      "id": "aV94FZkdIkNW",
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['@seananmcguire my best friend Carina is one here in San Francisco. Let me know if you want to get I touch. :)', 'That also means, imma go back to being more twitter active :D\\nCause I know everyone missed me ;) xD', '@MsKristinKreuk Hugs ang Kisses from the philippines :)', 'Please comment on what you think of what I wrote so far in the twitlonger :)', 'This girl :)  ', \"@grrl_afraid Oh course, I gained weight bcus I used to be a rubbish veggie but now I've learned to balance everything now! :-)\", '@Satbains1 Congratulations Sat on your 3rd honorary degree from everyone at Alacer :)', '@Geordnet hehe cool :)', '@Wilma2207fWilma haha! Thank you! :) üç∞', 'Hi BAM ! @BarsAndMelody \\nCan you follow my bestfriend @969Horan696 ? \\nShe loves you a lot :) \\nSee you in Warsaw &lt;3 \\nLove you &lt;3 x10']\n",
            "--------\n",
            "['@Sanza_T @LeratoTmohale Does the bag do the job Sanza?  :-)', '@WeAlwaysChillin This sounds nice :D', \"@wishinguponstar We couldn't have said it better ourselves, Kelly! So glad you're enjoying your nibbles :)\", 'Chaerin unnie : )', 'A very productive day so far :) Happy Days...!!  :) :) but my head is spinning with things, those voices keep calling..!!! Lol \\U000fe334', '@twentyonepilots @fujirock_jp tylers hipster glasses :D', '@clivewalker near enough to Dartmoor :)', '@simonxxx_ follback :)', 'Stats for the day have arrived. 2 new followers and NO unfollowers :) via .', 'ROFL! Shades of Grey - netsec edition :-) ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "492ae463-b611-4292-9ad2-b778856bf8bc"
      },
      "source": [
        "**1.6) Remove all stop words**"
      ],
      "id": "492ae463-b611-4292-9ad2-b778856bf8bc"
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7XKkCUq3Cjq",
        "outputId": "6b49dc9c-77a9-4df7-e97e-8dc333dd7b97"
      },
      "id": "P7XKkCUq3Cjq",
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "961d73fd-a662-46f2-85a2-83bf6b978189"
      },
      "source": [
        "#code here\n",
        "\n",
        "stopword = nltk.corpus.stopwords.words('english')\n",
        "x_dev = [[word for word in word_tokenize(tweet) if word not in stopword] for tweet in x_dev]\n",
        "x_test = [[word for word in word_tokenize(tweet) if word not in stopword] for tweet in x_test]"
      ],
      "id": "961d73fd-a662-46f2-85a2-83bf6b978189",
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "169bf8ad-f7ba-4e67-a1a0-92fcdd193ab9"
      },
      "source": [
        "**1.7) Remove all punctuations**"
      ],
      "id": "169bf8ad-f7ba-4e67-a1a0-92fcdd193ab9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "774743e0-8cf0-4dbb-a6fa-006ff076bb9e"
      },
      "source": [
        "#code here\n",
        "\n",
        "x_dev = [' '.join(tweet).translate(str.maketrans('','',string.punctuation)) for tweet in x_dev]\n",
        "x_test = [' '.join(tweet).translate(str.maketrans('','',string.punctuation)) for tweet in x_test]"
      ],
      "id": "774743e0-8cf0-4dbb-a6fa-006ff076bb9e",
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (x_dev[:10])\n",
        "print (\"----------\")\n",
        "print (x_test[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXijhF3e4XRg",
        "outputId": "edac2343-1eb1-4fb5-cb84-2d19fedbe18a"
      },
      "id": "qXijhF3e4XRg",
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' seananmcguire best friend Carina one San Francisco  Let know want get I touch   ', 'That also means  imma go back twitter active  D Cause I know everyone missed   xD', ' MsKristinKreuk Hugs ang Kisses philippines  ', 'Please comment think I wrote far twitlonger  ', 'This girl  ', ' grrlafraid Oh course  I gained weight bcus I used rubbish veggie I ve learned balance everything    ', ' Satbains1 Congratulations Sat 3rd honorary degree everyone Alacer  ', ' Geordnet hehe cool  ', ' Wilma2207fWilma haha  Thank    üç∞', 'Hi BAM   BarsAndMelody Can follow bestfriend  969Horan696  She loves lot   See Warsaw  lt  3 Love  lt  3 x10']\n",
            "----------\n",
            "[' SanzaT  LeratoTmohale Does bag job Sanza    ', ' WeAlwaysChillin This sounds nice  D', ' wishinguponstar We could nt said better  Kelly  So glad re enjoying nibbles  ', 'Chaerin unnie  ', 'A productive day far   Happy Days        head spinning things  voices keep calling    Lol \\U000fe334', ' twentyonepilots  fujirockjp tylers hipster glasses  D', ' clivewalker near enough Dartmoor  ', ' simonxxx follback  ', 'Stats day arrived  2 new followers NO unfollowers   via ', 'ROFL  Shades Grey  netsec edition   ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2f1af18-0c07-4ffb-994e-daead4740a53"
      },
      "source": [
        "**1.8) Apply stemming on the development & test datasets using Porter algorithm**"
      ],
      "id": "b2f1af18-0c07-4ffb-994e-daead4740a53"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c84a52f6-a62a-4033-8d1d-239ff6904248"
      },
      "source": [
        "#code here\n",
        "stemmer = nltk.stem.PorterStemmer()\n",
        "x_dev = [' '.join([stemmer.stem(word) for word in word_tokenize(tweet)]) for tweet in x_dev]\n",
        "x_test = [' '.join([stemmer.stem(word) for word in word_tokenize(tweet)]) for tweet in x_test]"
      ],
      "id": "c84a52f6-a62a-4033-8d1d-239ff6904248",
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (x_dev[:10])\n",
        "print ('--------')\n",
        "print (x_test[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVA6ERUCIuIx",
        "outputId": "981ce5c4-4c17-41d0-f308-f121cd8410ec"
      },
      "id": "sVA6ERUCIuIx",
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['seananmcguir best friend carina one san francisco let know want get I touch', 'that also mean imma go back twitter activ D caus I know everyon miss xD', 'mskristinkreuk hug ang kiss philippin', 'pleas comment think I wrote far twitlong', 'thi girl', 'grrlafraid Oh cours I gain weight bcu I use rubbish veggi I ve learn balanc everyth', 'satbains1 congratul sat 3rd honorari degre everyon alac', 'geordnet hehe cool', 'wilma2207fwilma haha thank üç∞', 'Hi bam barsandmelodi can follow bestfriend 969horan696 she love lot see warsaw lt 3 love lt 3 x10']\n",
            "--------\n",
            "['sanzat leratotmohal doe bag job sanza', 'wealwayschillin thi sound nice D', 'wishinguponstar We could nt said better kelli So glad re enjoy nibbl', 'chaerin unni', 'A product day far happi day head spin thing voic keep call lol \\U000fe334', 'twentyonepilot fujirockjp tyler hipster glass D', 'clivewalk near enough dartmoor', 'simonxxx follback', 'stat day arriv 2 new follow NO unfollow via', 'rofl shade grey netsec edit']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "687e23ef-dafd-4183-b2f1-86089e281dd8"
      },
      "source": [
        "#### **Model training**"
      ],
      "id": "687e23ef-dafd-4183-b2f1-86089e281dd8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c40fa44-01ad-4788-98b9-9c8f0c1252ef"
      },
      "source": [
        "**1.9) Create bag of words features for each tweet in the development dataset**"
      ],
      "id": "0c40fa44-01ad-4788-98b9-9c8f0c1252ef"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c17c6b99-9dfb-4d30-9e03-d596a9da880a"
      },
      "source": [
        "#code here\n",
        "\n",
        "vector_bow = CountVectorizer()\n",
        "x_dev_bow = vector_bow.fit_transform(x_dev)\n",
        "x_test_bow = vector_bow.transform(x_test)"
      ],
      "id": "c17c6b99-9dfb-4d30-9e03-d596a9da880a",
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4baf65cd-019b-4ff4-b93c-3ca8cfffca8e"
      },
      "source": [
        "**1.10) Train a supervised learning model of choice on the development dataset**"
      ],
      "id": "4baf65cd-019b-4ff4-b93c-3ca8cfffca8e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3433a6b0-408d-462e-9072-3495b21bc97b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f1f592b-f7d6-4589-c3be-a774e988a447"
      },
      "source": [
        "#code here\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(x_dev_bow, y_dev)"
      ],
      "id": "3433a6b0-408d-462e-9072-3495b21bc97b",
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c16c6f6-7ab2-4d7a-b9dc-098a72381340"
      },
      "source": [
        "**1.11) Create TF-IDF features for each tweet in the development dataset**"
      ],
      "id": "1c16c6f6-7ab2-4d7a-b9dc-098a72381340"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b417843-ffc4-4614-b2ef-964f8ec3e510"
      },
      "source": [
        "#code here\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_dev = tfidf.fit_transform(x_dev)\n",
        "tfidf_test = tfidf.transform(x_test)"
      ],
      "id": "7b417843-ffc4-4614-b2ef-964f8ec3e510",
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea3c9776-aad9-4eda-b3c2-d9f6b3e52427"
      },
      "source": [
        "**1.12) Train the same supervised learning algorithm on the development dataset with TF-IDF features**"
      ],
      "id": "ea3c9776-aad9-4eda-b3c2-d9f6b3e52427"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8c7fe8b-61de-4daa-a338-74295a4902ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43ecb5aa-b0bc-4ca3-9b97-745e304c1b03"
      },
      "source": [
        "#code here\n",
        "\n",
        "model_tfidf = LogisticRegression()\n",
        "model_tfidf.fit(tfidf_dev, y_dev)"
      ],
      "id": "b8c7fe8b-61de-4daa-a338-74295a4902ce",
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab0129e7-a0ea-473e-9ad1-667b44a13a92"
      },
      "source": [
        "**1.13) Compare the performance of the two models on the test dataset**"
      ],
      "id": "ab0129e7-a0ea-473e-9ad1-667b44a13a92"
    },
    {
      "cell_type": "code",
      "source": [
        "print (x_test_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUL1XOjI8f6J",
        "outputId": "341b55fd-4204-4659-b84e-f0b08006ebb1"
      },
      "id": "GUL1XOjI8f6J",
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 1333)\t1\n",
            "  (0, 3609)\t1\n",
            "  (0, 6618)\t1\n",
            "  (1, 9067)\t1\n",
            "  (1, 11889)\t1\n",
            "  (1, 12820)\t1\n",
            "  (2, 1648)\t1\n",
            "  (2, 2924)\t1\n",
            "  (2, 4046)\t1\n",
            "  (2, 5010)\t1\n",
            "  (2, 9063)\t1\n",
            "  (2, 9268)\t1\n",
            "  (2, 10546)\t1\n",
            "  (2, 11049)\t1\n",
            "  (2, 11770)\t1\n",
            "  (2, 13806)\t1\n",
            "  (3, 13413)\t1\n",
            "  (4, 2195)\t1\n",
            "  (4, 3261)\t2\n",
            "  (4, 4329)\t1\n",
            "  (4, 5392)\t1\n",
            "  (4, 5487)\t1\n",
            "  (4, 6951)\t1\n",
            "  (4, 7645)\t1\n",
            "  (4, 10273)\t1\n",
            "  :\t:\n",
            "  (1994, 10273)\t1\n",
            "  (1994, 10546)\t1\n",
            "  (1994, 13359)\t1\n",
            "  (1994, 13385)\t1\n",
            "  (1994, 13471)\t1\n",
            "  (1995, 7762)\t2\n",
            "  (1995, 8719)\t1\n",
            "  (1995, 11770)\t1\n",
            "  (1995, 14494)\t1\n",
            "  (1996, 8719)\t1\n",
            "  (1996, 9268)\t1\n",
            "  (1996, 12346)\t1\n",
            "  (1996, 13863)\t1\n",
            "  (1997, 11168)\t1\n",
            "  (1997, 11826)\t1\n",
            "  (1998, 4616)\t1\n",
            "  (1998, 4936)\t1\n",
            "  (1998, 9665)\t1\n",
            "  (1999, 2414)\t1\n",
            "  (1999, 4630)\t1\n",
            "  (1999, 7259)\t1\n",
            "  (1999, 7671)\t1\n",
            "  (1999, 9443)\t1\n",
            "  (1999, 12206)\t1\n",
            "  (1999, 13013)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a64ca176-dab8-4965-a85d-dcf9dc013717",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bc6b48a-363b-4a01-c14d-8889d2178b74"
      },
      "source": [
        "#code here\n",
        "\n",
        "model.score (x_test_bow, y_test)"
      ],
      "id": "a64ca176-dab8-4965-a85d-dcf9dc013717",
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7595"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_tfidf.score (tfidf_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeYrfm747FGQ",
        "outputId": "59a84120-5c03-4a0b-c55f-1bdd0c22bab0"
      },
      "id": "MeYrfm747FGQ",
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.766"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### TFIDF model performs better than the BOW model as seen from the score values of the models (0.766: TFIDF vs. 0.7595: BOW)"
      ],
      "metadata": {
        "id": "Ma-83K1jBxnr"
      },
      "id": "Ma-83K1jBxnr"
    }
  ]
}